# Stressanalyse - Diagnostisches Praktikum

Psychometrische Analysen fÃ¼r Stressskalen und Coping-Strategien.

## Projektstruktur (Neu Organisiert)

```
.
â”œâ”€â”€ run_all.R                 # Master-Skript (fÃ¼hrt alle Analysen aus)
â”œâ”€â”€ README.md                 # Diese Datei
â”œâ”€â”€ renv.lock                 # R-Paket-AbhÃ¤ngigkeiten
â”‚
â”œâ”€â”€ src/                      # Alle Analyseskripte
â”‚   â”œâ”€â”€ 00_clean_data.R       # Datenbereinigung
â”‚   â”œâ”€â”€ 01_setup_and_scales.R # Skalen konstruieren
â”‚   â”œâ”€â”€ 02_descriptive_plots.R
â”‚   â”œâ”€â”€ 03_reliability.R
â”‚   â”œâ”€â”€ 04_validity_main.R
â”‚   â”œâ”€â”€ 05-08_*.R             # Subgruppenanalysen
â”‚   â”œâ”€â”€ 09_justification.R
â”‚   â”œâ”€â”€ 10_final_comparison.R
â”‚   â”œâ”€â”€ 11_normalization_and_tables.R  # â­ NEU: ZusammengefÃ¼hrt
â”‚   â””â”€â”€ 13_final_scale_metrics.R
â”‚
â”œâ”€â”€ data/                     # Daten & Workspaces
â”‚   â”œâ”€â”€ data_stressskala_*.csv  # Rohdaten (Input)
â”‚   â”œâ”€â”€ data.csv              # Bereinigte Daten
â”‚   â”œâ”€â”€ 01_scales.RData       # Workspace mit allen Skalen
â”‚   â”œâ”€â”€ 11_normierung.RData   # Normierungsanalysen
â”‚   â””â”€â”€ codebook.xlsx         # Codebuch
â”‚
â”œâ”€â”€ output/                   # Analyseergebnisse (CSV)
â”‚   â”œâ”€â”€ normierung_*.csv      # Gruppenvergleiche
â”‚   â””â”€â”€ normtabellen/         # â­ NEU: Normtabellen als CSV
â”‚       â”œâ”€â”€ normtabelle_stresssymptome.csv
â”‚       â”œâ”€â”€ normtabelle_coping_*.csv
â”‚       â””â”€â”€ normtabelle_stressbelastung_*.csv
â”‚
â””â”€â”€ plots/                    # Visualisierungen (PNG)
    â”œâ”€â”€ plot_01-04_*.png      # Deskriptive Statistiken
    â”œâ”€â”€ plot_05-12_*.png      # ReliabilitÃ¤t
    â”œâ”€â”€ plot_13-19_*.png      # ValiditÃ¤t
    â””â”€â”€ plot_20-39_*.png      # Subgruppenanalysen
```

## Wichtige Ã„nderungen (2025-12-19)

### âœ… DurchgefÃ¼hrte Verbesserungen

1. **Projektstruktur vereinfacht**
   - Alle R-Skripte in `src/` Verzeichnis verschoben
   - Bessere Trennung: Code (src/), Daten (data/), Output (output/, plots/)

2. **Normierungsskripte zusammengefÃ¼hrt**
   - `11_normalization_analysis.R` + `12_create_norm_tables.R` 
     â†’ `11_normalization_and_tables.R`
   - README-Dokumentation als Kommentare ins Skript integriert
   - Reduziert KomplexitÃ¤t von 14 auf 13 Skripte

3. **CSV statt PNG fÃ¼r Normtabellen**
   - Einfachere Weiterverarbeitung (Excel, R, Word)
   - Bessere Integration in Test-Manual
   - Speicherort: `output/normtabellen/*.csv`

4. **Zentrale Datenpfad-Konfiguration**
   - Alle Pfade zu Rohdaten in `run_all.R` definiert
   - Bei neuen Daten: Nur eine Stelle Ã¤ndern
   - Variablen: `RAW_DATA_FILE`, `CLEAN_DATA_FILE`, `WORKSPACE_FILE`

5. **Dokumentation verbessert**
   - README mit Projektstruktur und Verwendung
   - Umfassende Inline-Dokumentation in `11_normalization_and_tables.R`

6. **â­ NEU: Automatisches Analyse-Logging**
   - Alle Konsolenausgaben werden in Log-Datei gespeichert
   - Speicherort: `output/analysis_log_YYYYMMDD_HHMMSS.txt`
   - EnthÃ¤lt vollstÃ¤ndige Dokumentation aller Analyseschritte
   - Gleichzeitige Ausgabe an Konsole und Datei (split = TRUE)

7. **â­ NEU: Automatische DatenqualitÃ¤tsfilterung**
   - Konsistente Ausreisser werden automatisch entfernt (â‰¥2 Methoden)
   - Dokumentation problematischer Items mit niedriger Varianz
   - Transparente Berichterstattung Ã¼ber alle Filterungsschritte
   - Finale StichprobengrÃ¶ÃŸe klar dokumentiert

## Schnellstart

### 1. VollstÃ¤ndige Analyse ausfÃ¼hren

```r
source("run_all.R")
```

Dies fÃ¼hrt alle 13 Analyseschritte nacheinander aus (~5-10 Minuten).

**NEU:** Die gesamte Konsolenausgabe wird automatisch in einer Log-Datei gespeichert:
- Speicherort: `output/analysis_log_YYYYMMDD_HHMMSS.txt`
- EnthÃ¤lt: Alle Statistiken, Warnungen und Ergebnisse
- Format: Zeitgestempelt und vollstÃ¤ndig durchsuchbar

### 2. Nur bestimmte Schritte ausfÃ¼hren

```r
# Zuerst: Setup laden
load("data/01_scales.RData")

# Dann: Einzelne Analysen
source("src/03_reliability.R")
source("src/11_normalization_and_tables.R")
```

### 3. Bei neuen Daten

Ã„ndern Sie in `run_all.R`:

```r
RAW_DATA_FILE <- "data/data_stressskala_2025-XX-XX_XX-XX.csv"
```

Dann `source("run_all.R")` ausfÃ¼hren.

## Analysepipeline

| Schritt | Skript | Zweck | Output |
|---------|--------|-------|--------|
| 0 | `00_clean_data.R` | Daten bereinigen | `data/data.csv` |
| 1 | `01_setup_and_scales.R` | Skalen + QualitÃ¤tsfilterung | `data/01_scales.RData` |
| 2-4 | `02-04_*.R` | Deskriptiv, ReliabilitÃ¤t, ValiditÃ¤t | Plots 01-19 |
| 5-8 | `05-08_*.R` | Subgruppenanalysen | Plots 20-39, CSV |
| 9-10 | `09-10_*.R` | Itemauswahl, Vergleiche | CSV-Reports |
| 11 | `11_normalization_and_tables.R` | Normierung | CSV-Normtabellen |
| 12 | `12_final_scale_metrics.R` | Finale Metriken | CSV-Reports |
| - | `run_all.R` (automatisch) | Alle Schritte | `output/analysis_log_*.txt` |

## Normtabellen verwenden

Die Normtabellen liegen als CSV-Dateien vor:

```r
# In R Ã¶ffnen
norm <- read.csv("output/normtabellen/normtabelle_stresssymptome.csv", 
                 comment.char = "#")

# In Excel Ã¶ffnen (Doppelklick oder Import)
```

### Struktur der Normtabellen

```
# Titel,Stresssymptome (Kurzskala),
# Untertitel,Gemeinsame Norm fÃ¼r gesamte Stichprobe,
# N,200,
# Mittelwert,2.45,
# SD,0.82,
# Min,1.0,
# Max,5.0,
,
Rohwert,Z_Wert,T_Wert
1.2,-1.52,35
1.3,-1.40,36
...
```

- **Zeilen 1-7**: Metadaten (beginnen mit #)
- **Zeile 8**: Leer
- **Zeile 9+**: SpaltenÃ¼berschriften und Normwerte

### Normwerte nachschlagen

1. Rohwert berechnen (z.B. Mittelwert der 5 Items)
2. Passende Tabelle wÃ¤hlen:
   - Stressbelastung â†’ nach Alter (jung/mittel/alt)
   - Coping Aktiv â†’ nach Geschlecht
   - Andere â†’ gemeinsame Norm
3. Rohwert in Tabelle suchen
4. Z-Wert und T-Wert ablesen

**Beispiel:**
- Stresssymptome Rohwert = 3.2
- Tabelle: `normtabelle_stresssymptome.csv`
- Ergebnis: Z = +0.91, T = 59
- Interpretation: Ãœberdurchschnittlich (knapp 1 SD Ã¼ber Mittelwert)

## Empfehlungen fÃ¼r weitere Verbesserungen

### ğŸ¯ Hohe PrioritÃ¤t

1. **Funktionsbibliothek erstellen**
   ```r
   # src/utils/functions.R
   # Alle wiederverwendeten Funktionen (z.B. print_section, cohens_d)
   source("src/utils/functions.R")  # In jedem Skript
   ```

2. **Konfigurationsdatei einfÃ¼hren**
   ```r
   # config.R
   CONFIG <- list(
     data = list(
       raw = "data/data_stressskala_2025-12-18_10-13.csv",
       clean = "data/data.csv"
     ),
     output = list(
       plots = "plots",
       tables = "output/normtabellen"
     ),
     analysis = list(
       min_group_size = 20,
       alpha_level = 0.05,
       effect_size_threshold = 0.3
     )
   )
   ```

3. **Paket-AbhÃ¤ngigkeiten dokumentieren**
   ```r
   # src/00_packages.R
   required_packages <- c("tidyverse", "lavaan", "psych", "gridExtra")
   
   for (pkg in required_packages) {
     if (!require(pkg, character.only = TRUE)) {
       renv::install(pkg)
       library(pkg, character.only = TRUE)
     }
   }
   ```

4. **Logging verbessern**
   - Zeitstempel fÃ¼r jeden Schritt
   - Warnungen und Fehler in Log-Datei speichern
   - Zusammenfassung am Ende

### ğŸ’¡ Mittlere PrioritÃ¤t

5. **Unit-Tests hinzufÃ¼gen**
   ```r
   # tests/test_functions.R
   library(testthat)
   
   test_that("cohens_d berechnet korrekt", {
     x <- c(1, 2, 3, 4, 5)
     y <- c(2, 3, 4, 5, 6)
     d <- cohens_d(x, y)
     expect_equal(round(d, 2), -0.63)
   })
   ```

6. **Reproduzierbarkeit sichern**
   ```r
   # Am Anfang jedes Skripts
   set.seed(42)  # FÃ¼r reproduzierbare Zufallszahlen
   
   # Session Info speichern
   writeLines(capture.output(sessionInfo()), 
              "output/session_info.txt")
   ```

7. **Datenvalidierung**
   ```r
   # src/utils/validate_data.R
   validate_data <- function(data) {
     # PrÃ¼fe:
     # - Pflichtfelder vorhanden
     # - Wertebereich korrekt (1-5 fÃ¼r Likert)
     # - Keine ungÃ¼ltigen Werte
     # - MindeststichprobengrÃ¶ÃŸe
   }
   ```

8. **Parallelisierung fÃ¼r schnellere AusfÃ¼hrung**
   ```r
   library(parallel)
   cl <- makeCluster(detectCores() - 1)
   # Parallele AusfÃ¼hrung von unabhÃ¤ngigen Analysen
   # z.B. Subgruppenanalysen 05-07 gleichzeitig
   stopCluster(cl)
   ```

### ğŸ”§ Niedrige PrioritÃ¤t (Nice-to-have)

9. **RMarkdown-Reports**
   - Automatische PDF/HTML-Berichte
   - Tabellen und Plots integriert
   - FÃ¼r Seminararbeit oder PrÃ¤sentation

10. **Interaktive Plots**
    ```r
    library(plotly)
    library(shiny)
    # Interaktive Normtabellen-Abfrage
    ```

11. **Code-Stil vereinheitlichen**
    - styler-Paket verwenden
    - lintr fÃ¼r Code-QualitÃ¤t
    - Konsistente Namenskonventionen

12. **Git-Versionskontrolle**
    ```bash
    git init
    git add .
    git commit -m "Initial commit: Cleaned project structure"
    ```

## Code-Vereinfachungen

### Wiederholter Code eliminieren

**Vorher (in mehreren Skripten):**
```r
# Levene-Test Implementierung in 11_*.R
# print_section Funktion in vielen Skripten
# cohens_d Funktion mehrfach definiert
```

**Nachher:**
```r
# src/utils/functions.R
source("src/utils/functions.R")  # Einmal definieren
```

### Datenlade-Logik vereinfachen

**Vorher:**
```r
# In jedem Skript:
load("data/01_scales.RData")
```

**Besser:**
```r
# src/utils/load_data.R
load_project_data <- function(step = 1) {
  if (step == 1) {
    load("data/01_scales.RData", envir = .GlobalEnv)
  } else if (step == 11) {
    load("data/11_normierung.RData", envir = .GlobalEnv)
  }
  cat("âœ“ Daten geladen\n")
}
```

### Magic Numbers vermeiden

**Vorher:**
```r
if (abs(d) >= 0.3) {  # Was bedeutet 0.3?
  empfehlung <- "Getrennte Normen"
}
```

**Besser:**
```r
EFFECT_SIZE_THRESHOLD_SMALL <- 0.3
EFFECT_SIZE_THRESHOLD_MEDIUM <- 0.5

if (abs(d) >= EFFECT_SIZE_THRESHOLD_SMALL) {
  empfehlung <- "Getrennte Normen"
}
```

## DatenqualitÃ¤t und Filterung

### Automatische QualitÃ¤tsprÃ¼fungen (Schritt 1)

Das Skript `01_setup_and_scales.R` fÃ¼hrt umfassende QualitÃ¤tsprÃ¼fungen durch:

1. **Varianzanalyse**
   - PrÃ¼ft alle Items auf ausreichende Streuung
   - Identifiziert Items mit SD < 0.5, Range < 3, oder Decken-/Bodeneffekten
   - Dokumentiert problematische Items (werden NICHT automatisch entfernt)

2. **Ausreisser-Detektion (3 Methoden)**
   - Z-Score-Methode: |z| > 3.29
   - IQR-Methode: Werte auÃŸerhalb Q1-1.5Ã—IQR bis Q3+1.5Ã—IQR
   - Mahalanobis-Distanz: Multivariate Ausreisser
   
3. **Automatische Filterung**
   - âœ… **Entfernt**: Konsistente Ausreisser (â‰¥2 Methoden stimmen Ã¼berein)
   - ğŸ“ **Dokumentiert**: Items mit Varianzproblemen (fÃ¼r Itemauswahl in Schritt 9)
   - ğŸ“Š **Berichtet**: Alle Filterungsschritte im Analysis-Log

### Wo finde ich die Ergebnisse?

**Im Analysis-Log** (`output/analysis_log_*.txt`):
- Sektion "VARIANZANALYSE DER ITEMS": Detaillierte Item-Statistiken
- Sektion "AUSREISSER-ANALYSE": 3 Detektionsmethoden mit Ergebnissen
- Sektion "DATENFILTERUNG": Zusammenfassung der entfernten FÃ¤lle

**Finale StichprobengrÃ¶ÃŸe**: Nach allen Filtern dokumentiert

## FAQ

**Q: Wie aktualisiere ich die Daten?**  
A: Neue CSV-Datei in `data/` legen, Pfad in `run_all.R` anpassen, `source("run_all.R")` ausfÃ¼hren.

**Q: Wie fÃ¼ge ich eine neue Analyse hinzu?**  
A: Neues Skript in `src/`, load("data/01_scales.RData") am Anfang, in `run_all.R` einbinden.

**Q: Warum CSV statt PNG fÃ¼r Normtabellen?**  
A: CSV-Dateien kÃ¶nnen direkt in Excel, Word-Tabellen oder andere Tools importiert werden. Einfacher fÃ¼r Test-Manuals.

**Q: Kann ich einzelne Schritte Ã¼berspringen?**  
A: Ja, aber beachten Sie AbhÃ¤ngigkeiten. Alle Schritte 2-12 benÃ¶tigen Schritt 1 (01_scales.RData).

**Q: Wie installiere ich fehlende Pakete?**  
A: `renv::restore()` installiert alle in renv.lock definierten Pakete.

**Q: Wo finde ich das vollstÃ¤ndige Analysis-Log?**  
A: Nach jedem `run_all.R` Durchlauf in `output/analysis_log_YYYYMMDD_HHMMSS.txt`

**Q: Werden Ausreisser automatisch entfernt?**  
A: Ja, aber nur konsistente Ausreisser die von â‰¥2 unabhÃ¤ngigen Methoden identifiziert wurden. Dies wird transparent dokumentiert.

**Q: Was passiert mit Items mit niedriger Varianz?**  
A: Sie werden dokumentiert, aber NICHT automatisch entfernt. Die Itemauswahl fÃ¼r Kurzskalen erfolgt in Schritt 9 basierend auf psychometrischen Kriterien.

## Dokumentation & Literatur

- **Testtheorie**: Lienert & Raatz (1998) - Testaufbau und Testanalyse
- **EffektgrÃ¶ÃŸen**: Cohen (1988) - Statistical Power Analysis
- **Normierung**: Lenhard & Lenhard (2014) - Berechnung der Normwerte

## Kontakt & Support

Bei Fragen zum Code oder den Analysen:
- ÃœberprÃ¼fen Sie die Inline-Kommentare in den Skripten
- Konsultieren Sie die Output-CSV-Dateien
- Lesen Sie `src/11_normalization_and_tables.R` fÃ¼r Details zur Normierung

## Lizenz

Akademisches Projekt - Diagnostisches Praktikum 2025
